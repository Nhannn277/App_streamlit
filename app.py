import os
import pandas as pd
import pickle
import numpy as np
import streamlit as st
import seaborn as sns
import plotly.express as px
from streamlit_option_menu import option_menu
import matplotlib.pyplot as plt

import base64
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder



from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import io
from sklearn.tree import plot_tree



st.set_page_config(page_title="Health Assistant",
                   layout="wide",
                   page_icon="üßë‚Äç‚öïÔ∏è")



working_dir = os.path.dirname(os.path.abspath(__file__))

heart_disease_model = pickle.load(open(f'{working_dir}/saved_models/heart_disease_model.sav', 'rb'))

with st.sidebar:
    selected = option_menu('Menu',
                           ['Upload CSV',
                            'Heart Disease Prediction',
                            'Clean Data'],
                           menu_icon='hospital-fill',
                           icons=['cloud-upload', 'heart','data'],
                           default_index=0)


#----------------------------------------------------------------------------------------------------------    

if selected == 'Upload CSV':
    
    st.title('Upload CSV')

    uploaded_files = st.file_uploader("Choose a CSV file", accept_multiple_files=True)
    
    if uploaded_files:
        for uploaded_file in uploaded_files:
            df = pd.read_csv(uploaded_file)
            st.write(uploaded_file.name)
            st.write(df.head(1))
            col1, col2 = st.columns(2)
  
        ml_algorithm = st.sidebar.selectbox("Ch·ªçn thu·∫≠t to√°n", ["Linear Regression", "Logistic Regression", "KNN", "Decision Tree"])

        if ml_algorithm == "Linear Regression":
            dependent_var = st.sidebar.selectbox("Ch·ªçn bi·∫øn ph·ª• thu·ªôc", df.columns)
            independent_vars = st.sidebar.multiselect("Ch·ªçn bi·∫øn ƒë·ªôc l·∫≠p", df.columns.drop(dependent_var))

            if st.sidebar.button("D·ª± ƒëo√°n"):
                X = df[independent_vars]
                y = df[dependent_var]

                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

                model = LinearRegression()
                model.fit(X_train, y_train)

                y_pred = model.predict(X_test)

                st.subheader("K·∫øt qu·∫£ d·ª± ƒëo√°n vs Gi√° tr·ªã th·ª±c t·∫ø")
                result_df = pd.DataFrame({"Th·ª±c t·∫ø": y_test, "D·ª± ƒëo√°n": y_pred})
                st.write(result_df)

                plt.figure(figsize=(10, 6))
                sns.scatterplot(x=y_test, y=y_pred)
                sns.lineplot(x=y_test, y=y_test, color='red', label='Linear line')
                plt.xlabel("Th·ª±c t·∫ø")
                plt.ylabel("D·ª± ƒëo√°n")
                plt.title("Bi·ªÉu ƒë·ªì d·ª± ƒëo√°n vs Th·ª±c t·∫ø")
                plt.legend()
                st.pyplot(plt)

        elif ml_algorithm == "Logistic Regression":
            dependent_var = st.sidebar.selectbox("Ch·ªçn bi·∫øn ph·ª• thu·ªôc (Ch·ªâ ph√¢n lo·∫°i)", df.columns)
            independent_vars = st.sidebar.multiselect("Ch·ªçn bi·∫øn ƒë·ªôc l·∫≠p", df.columns.drop(dependent_var))

            if st.sidebar.button("D·ª± ƒëo√°n"):
                X = df[independent_vars]
                y = df[dependent_var]

                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

                model = LogisticRegression()
                model.fit(X_train, y_train)

                y_pred = model.predict(X_test)

                st.subheader("K·∫øt qu·∫£ d·ª± ƒëo√°n")
                result_df = pd.DataFrame({"Th·ª±c t·∫ø": y_test, "D·ª± ƒëo√°n": y_pred})
                st.write(result_df)

                plt.figure(figsize=(10, 6))
                sns.heatmap(pd.crosstab(y_test, y_pred), annot=True, fmt='d')
                plt.title("Ma tr·∫≠n Confusion")
                plt.xlabel("D·ª± ƒëo√°n")
                plt.ylabel("Th·ª±c t·∫ø")
                st.pyplot(plt)

        elif ml_algorithm == "KNN":
            dependent_var = st.sidebar.selectbox("Ch·ªçn bi·∫øn ph·ª• thu·ªôc (Ch·ªâ ph√¢n lo·∫°i)", df.columns)
            independent_vars = st.sidebar.multiselect("Ch·ªçn bi·∫øn ƒë·ªôc l·∫≠p", df.columns.drop(dependent_var))

            if st.sidebar.button("D·ª± ƒëo√°n"):
                X = df[independent_vars]
                y = df[dependent_var]

                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

                model = KNeighborsClassifier()
                model.fit(X_train, y_train)

                y_pred = model.predict(X_test)

                st.subheader("K·∫øt qu·∫£ d·ª± ƒëo√°n")
                result_df = pd.DataFrame({"Th·ª±c t·∫ø": y_test, "D·ª± ƒëo√°n": y_pred})
                st.write(result_df)
                plt.figure(figsize=(10, 6))
                sns.heatmap(pd.crosstab(y_test, y_pred), annot=True, fmt='d')
                plt.title("Ma tr·∫≠n Confusion")
                plt.xlabel("D·ª± ƒëo√°n")
                plt.ylabel("Th·ª±c t·∫ø")
                st.pyplot(plt)
        elif ml_algorithm == "Decision Tree":
            dependent_var = st.sidebar.selectbox("Ch·ªçn bi·∫øn ph·ª• thu·ªôc (Ch·ªâ ph√¢n lo·∫°i)", df.columns)
            independent_vars = st.sidebar.multiselect("Ch·ªçn bi·∫øn ƒë·ªôc l·∫≠p", df.columns.drop(dependent_var))

            if st.sidebar.button("D·ª± ƒëo√°n"):
                X = df[independent_vars]
                y = df[dependent_var]

                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

                model = DecisionTreeClassifier()
                model.fit(X_train, y_train)

                y_pred = model.predict(X_test)

                st.subheader("K·∫øt qu·∫£ d·ª± ƒëo√°n")
                result_df = pd.DataFrame({"Th·ª±c t·∫ø": y_test, "D·ª± ƒëo√°n": y_pred})
                st.write(result_df)

                # In ra c√¢y quy·∫øt ƒë·ªãnh
                plt.figure(figsize=(20, 10))
                plot_tree(model, filled=True, feature_names=X.columns.tolist(), class_names=y.unique().tolist())
                st.pyplot(plt)
    
#---------------
if selected == 'Heart Disease Prediction':

    # page title#
    st.title('Heart Disease Prediction using ML')

#     col1, col2, col3 = st.columns(3)

#     with col1:
#         age = st.text_input('Tu·ªïi')

#     with col2:
#         sex = st.text_input('Gi·ªõi t√≠nh (1 = Nam, 0 = N·ªØ)')

#     with col3:
#         cp = st.text_input('Lo·∫°i ƒëau ng·ª±c')

#     with col1:
#         trestbps = st.text_input('Huy·∫øt √°p l√∫c ngh·ªâ (t√≠nh b·∫±ng mm Hg)')

#     with col2:
#         chol = st.text_input('Cholestoral mg/dl')

#     with col3:
#         fbs = st.text_input('ƒê∆∞·ªùng trong m√°u > 120 mg/dl (1 = true; 0 = false)')

#     with col1:
#         restecg = st.text_input('K·∫øt qu·∫£ ƒëi·ªán t√¢m ƒë·ªì l√∫c ngh·ªâ ng∆°i')

#     with col2:
#         thalach = st.text_input('Nh·ªãp tim t·ªëi ƒëa ƒë·∫°t ƒë∆∞·ª£c')

#     with col3:
#         exang = st.text_input('T·∫≠p th·ªÉ d·ª•c c√≥ g√¢y ƒëau t·∫Øc ng·ª±c kh√¥ng (1 = C√≥; 0 = Kh√¥ng)')

#     with col1:
#         oldpeak = st.text_input('Ch√™nh l·ªách ƒëoan ST trong khi t·∫≠p th·ªÉ d·ª•c so v·ªõi l√∫c ngh·ªâ')

#     with col2:
#         slope = st.text_input('ƒê·ªô d·ªëc t·∫°i ƒë·ªânh c·ªßa ƒëo·∫°n ST khi t·∫≠p th·ªÉ d·ª•c')

#     with col3:
#         ca = st.text_input('S·ªë l∆∞·ª£ng ƒëo·∫°n m·∫°ch ch√≠nh')

#     with col1:
#         thal = st.text_input('1 = b√¨nh th∆∞·ªùng, 2 = l·ªói c·ªë ƒë·ªãnh, 3 = khi·∫øm khuy·∫øt c√≥ th·ªÉ ƒë·∫£o ng∆∞·ª£c')

#     # code for Prediction
#     heart_diagnosis = ''

#     # creating a button for Prediction

#     if st.button('D·ª± ƒëo√°n b·ªánh tim'):

#         user_input = [age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpeak, slope, ca, thal]

#         user_input = [float(x) for x in user_input]

#         heart_prediction = heart_disease_model.predict([user_input])

#         if heart_prediction[0] == 1:
#             heart_diagnosis = 'Ng∆∞·ªùi n√†y c√≥ m·∫Øc b·ªánh tim'
#         else:
#             heart_diagnosis = 'Ng∆∞·ªùi n√†y kh√¥ng m·∫Øc b·ªánh tim'

#     st.success(heart_diagnosis)

#----------------------------------------------------------------------------------------------------------    

if selected == 'Clean Data':
    
    st.title('Clean Data')

    
    uploaded_files = st.file_uploader("Choose a CSV file", accept_multiple_files=True)
    

    if uploaded_files:
        
        for uploaded_file in uploaded_files:
            df = pd.read_csv(uploaded_file)
            st.write(uploaded_file.name)
            st.write("Hi·ªÉn th·ªã 5 h√†ng ƒë·∫ßu ti√™n c·ªßa dataset")
            st.write(df.head(5))
            st.write("S·ªë h√†ng v√† s·ªë c·ªôt trong dataset")
            st.write(df.shape)
            st.write("Ki·ªÉu d·ªØ li·ªáu c·ªßa c√°c c·ªôt trong dataset")
            st.write(df.dtypes)
            st.write("Ki·ªÉm tra missing values")
            st.write(df.isnull().sum())
            st.write("M√¥ t·∫£ d·ªØ li·ªáu")
            st.write(df.describe())
           
            
            
            
            # H√†m x√≥a c·ªôt
            def remove_col(my_df, unwanted_col):
                my_df = my_df.drop(columns=unwanted_col, errors='ignore')
                return my_df
            
            # H√†m ƒëi·ªÅn gi√° tr·ªã null
            def fill_null_values(my_df, selected_columns):
                for col in selected_columns:
                    if my_df[col].dtype == "object":
                        mode_val = my_df[col].mode()[0]
                        my_df[col].fillna(mode_val, inplace=True)
                    if my_df[col].dtype == "int64" or my_df[col].dtype == "float64":  # N·∫øu c·ªôt l√† s·ªë
                        unique_values = my_df[col].dropna().unique()
                        if len(unique_values) == 2 and set(unique_values) == {0, 1}:  # N·∫øu ch·ªâ c√≥ 2 gi√° tr·ªã v√† l√† 0 ho·∫∑c 1
                            mode_val = my_df[col].mode()[0]  # L·∫•y mode (gi√° tr·ªã xu·∫•t hi·ªán nhi·ªÅu nh·∫•t)
                            my_df[col].fillna(mode_val, inplace=True)
                    if my_df[col].dtype == "int64" or my_df[col].dtype == "int32":  # N·∫øu c·ªôt l√† s·ªë nguy√™n
                        if my_df[col].nunique() > 2:  # N·∫øu c√≥ nhi·ªÅu h∆°n 2 gi√° tr·ªã kh√°c nhau
                            mean_val = my_df[col].mean().astype(int)  # L·∫•y gi√° tr·ªã trung b√¨nh ki·ªÉu int
                            # Thay th·∫ø c√°c gi√° tr·ªã 0 b·∫±ng gi√° tr·ªã trung b√¨nh
                            my_df[col] = my_df[col].replace(0, mean_val)
                            my_df[col].fillna(mean_val, inplace=True)  # ƒêi·ªÅn gi√° tr·ªã null b·∫±ng gi√° tr·ªã trung b√¨nh
                    if my_df[col].dtype == "float64" or my_df[col].dtype == "float32":  # N·∫øu c·ªôt l√† s·ªë th·ª±c
                        if my_df[col].nunique() > 2:  # N·∫øu c√≥ nhi·ªÅu h∆°n 2 gi√° tr·ªã kh√°c nhau
                            mean_val = my_df[col].mean().astype(float)  # L·∫•y gi√° tr·ªã trung b√¨nh ki·ªÉu float
                            # Thay th·∫ø c√°c gi√° tr·ªã 0 b·∫±ng gi√° tr·ªã trung b√¨nh
                            my_df[col] = my_df[col].replace(0, mean_val)
                            my_df[col].fillna(mean_val, inplace=True)  # ƒêi·ªÅn gi√° tr·ªã null b·∫±ng gi√° tr·ªã trung b√¨nh
                return my_df
            
            # H√†m √©p ki·ªÉu
            def convert_column_dtype(my_df, column, new_dtype):
                try:
                    if new_dtype == "int32":
                        # Fill NaN and inf with a placeholder value (here we use -1)
                        my_df[column].fillna(0, inplace=True)
                        my_df[column].replace([np.inf, -np.inf], 0, inplace=True)
                        my_df[column] = my_df[column].astype(np.float32).astype(np.int32)
                    elif new_dtype == "int64":
                        my_df[column].fillna(0, inplace=True)
                        my_df[column].replace([np.inf, -np.inf], 0, inplace=True)
                        my_df[column] = my_df[column].astype(np.float64).astype(np.int64)
                    elif new_dtype == "float32":
                        my_df[column].replace([np.inf, -np.inf], np.nan, inplace=True)
                        my_df[column] = my_df[column].astype(np.float32)
                    elif new_dtype == "float64":
                        my_df[column].replace([np.inf, -np.inf], np.nan, inplace=True)
                        my_df[column] = my_df[column].astype(np.float64)
                    elif new_dtype == "object":
                        my_df[column] = my_df[column].astype(str)
                except Exception as e:
                    st.error(f"Error converting column {column} to {new_dtype}: {e}")
                return my_df
            
            # H√†m check outliers
            def check_outliers_plot(my_df, selected_column):
                if my_df[selected_column].dtype == "int64" or my_df[selected_column].dtype == "float64" or my_df[selected_column].dtype == "float32" or my_df[selected_column].dtype == "int32":
                    # T√≠nh gi√° tr·ªã Q1, Q3 v√† IQR
                    Q1 = my_df[selected_column].quantile(0.25)
                    Q3 = my_df[selected_column].quantile(0.75)
                    IQR = Q3 - Q1
                    
                    # T√¨m gi√° tr·ªã ngo·∫°i l·ªá d∆∞·ªõi v√† tr√™n
                    lower_bound = Q1 - 1.5 * IQR
                    upper_bound = Q3 + 1.5 * IQR
                    
                    # T·∫°o DataFrame ch·ª©a th√¥ng tin v·ªÅ outlier
                    outliers = my_df[(my_df[selected_column] < lower_bound) | (my_df[selected_column] > upper_bound)]
                    
                    if outliers.empty:
                        st.write("No outliers found.")
                    else:
                        # V·∫Ω bi·ªÉu ƒë·ªì box plot
                        fig = px.box(my_df, y=selected_column, title=f'Box plot of {selected_column}')
                        st.plotly_chart(fig)
                    
            def remove_outliers(my_df, selected_column):
                # T√≠nh gi√° tr·ªã Q1, Q3 v√† IQR
                Q1 = my_df[selected_column].quantile(0.25)
                Q3 = my_df[selected_column].quantile(0.75)
                IQR = Q3 - Q1
                
                # T√¨m gi√° tr·ªã ngo·∫°i l·ªá d∆∞·ªõi v√† tr√™n
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                # Lo·∫°i b·ªè c√°c ngo·∫°i l·ªá kh·ªèi d·ªØ li·ªáu
                my_df = my_df[(my_df[selected_column] >= lower_bound) & (my_df[selected_column] <= upper_bound)]
                
                return my_df
                        
            # H√†m l∆∞u dataset
            def save_dataset(my_df, filename):
                my_df.to_csv(filename, index=False)
                st.success(f"Dataset saved as {filename}")
            
            # H√†m download dataset
            def get_download_link(my_df, filename, text):
                csv = my_df.to_csv(index=False)
                b64 = base64.b64encode(csv.encode()).decode()  # Encode to base64
                href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">{text}</a>'
                return href

            # H√†m x·ª≠ l√Ω duplicate
            def handle_duplicates(my_df):
                
                # Drop duplicates
                my_df.drop_duplicates(keep= 'first', inplace=True)
                
                return my_df  
                      
            # H√†m m√£ h√≥a bi·∫øn ph√¢n lo·∫°i b·∫±ng ph∆∞∆°ng ph√°p One-Hot Encoding
            def one_hot_encode(my_df, column):
                encoder = OneHotEncoder()
                encoded = encoder.fit_transform(my_df[[column]]).toarray()
                df_encoded = pd.DataFrame(encoded, columns=encoder.get_feature_names_out([column]))
                my_df = pd.concat([my_df, df_encoded], axis=1)
                my_df.drop(columns=[column], inplace=True)
                return my_df

            # H√†m m√£ h√≥a bi·∫øn ph√¢n lo·∫°i b·∫±ng ph∆∞∆°ng ph√°p Ordinal Encoding
            def ordinal_encode(my_df, column):
                encoder = OrdinalEncoder()
                my_df[[column]] = encoder.fit_transform(my_df[[column]])
                return my_df

            # H√†m m√£ h√≥a bi·∫øn ph√¢n lo·∫°i b·∫±ng ph∆∞∆°ng ph√°p Label Encoding
            def label_encode(my_df, column):
                encoder = LabelEncoder()
                my_df[column] = encoder.fit_transform(my_df[column])
                return my_df               
            
            # Ki·ªÉm tra n·∫øu session state ch∆∞a t·ªìn t·∫°i, kh·ªüi t·∫°o m·ªõi
            if 'my_df' not in st.session_state:
                st.session_state.my_df = pd.DataFrame()
                st.session_state.my_df = df.copy()
            if 'deleted_columns' not in st.session_state:
                st.session_state.deleted_columns = []    
            
            tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs(["Remove Columns", 
                                                                      "Fill Null Values", 
                                                                      "Handle duplicates", 
                                                                      "Remove Rows with Null", 
                                                                      "Change Data Types", 
                                                                      "Check Outliers", 
                                                                      "Encode Categorical Variables", 
                                                                      "Save dataset"])
        
            with tab1:
                st.write("Remove Columns")
                unwanted_col = st.multiselect("Remove column", st.session_state.my_df.columns, key="deleted_columns")
                if st.button('Remove'):
                    st.session_state.my_df = remove_col(st.session_state.my_df, unwanted_col)
                    st.session_state.deleted_columns.extend(unwanted_col)
                    st.write(st.session_state.my_df.head(5))

            with tab2:
                st.header("Fill Null Values")
                st.write(st.session_state.my_df.head(5))
                st.write("Choose columns to fill null values")
                selected_columns = st.multiselect("Columns", st.session_state.my_df.columns, key="fill_null_values")
                if st.button('Fill Null Values'):
                    # √Åp d·ª•ng h√†m fill_null_values cho c√°c c·ªôt ƒë√£ ch·ªçn
                    filled_df = fill_null_values(st.session_state.my_df, selected_columns)
                    # C·∫≠p nh·∫≠t l·∫°i DataFrame
                    st.session_state.my_df = filled_df
                    st.write("Null values filled for selected columns")
                    st.write(st.session_state.my_df.head(5))

            
            with tab3:
                st.header("Handle Duplicates")

                if st.button("Handle Duplicates"):
                    
                    duplicate = st.session_state.my_df[st.session_state.my_df.duplicated(keep=False)]
                    
                    if duplicate.empty:
                        st.write("Don't have duplicate")
                    else:
                        st.write('row sum: {}'.format(len(st.session_state.my_df)))
                        #st.write('Have {} duplicates'.format(df.duplicated().sum()))  
                        
                        st.session_state.my_df = handle_duplicates(st.session_state.my_df)
                        
                        st.write('number of goods remaining after processing', len(st.session_state.my_df))
                                    


            with tab4:
                st.header("Remove Rows with Null")
                
                col1 , col2 = st.columns(2)
    
                with col1:
                    st.write("Ki·ªÉm tra missing values")
                    st.write(st.session_state.my_df.isnull().sum())

                with col2:
                    selected_columns = st.multiselect("Select columns to remove rows with null values:", st.session_state.my_df.columns, key="RemoveRowsNull")
                    
                    # L·∫•y mask cho c√°c h√†ng c√≥ gi√° tr·ªã null trong c√°c c·ªôt ƒë√£ ch·ªçn
                    mask = st.session_state.my_df[selected_columns].isnull().any(axis=1)
                    
                    # L·∫•y DataFrame ch·ª©a c√°c h√†ng c√≥ gi√° tr·ªã null
                    rows_with_null = st.session_state.my_df[mask]
                    
                    if st.button("Remove Rows with Null"):
                        # X√≥a c√°c h√†ng c√≥ gi√° tr·ªã null
                        st.session_state.my_df = st.session_state.my_df.drop(rows_with_null.index)
                        st.write("Rows with null values removed successfully.")
            
            with tab5:
                st.header("Change Data Types")
                st.write("Choose column and new data type:")

                # Hi·ªÉn th·ªã danh s√°ch c√°c c·ªôt v√† ki·ªÉu d·ªØ li·ªáu hi·ªán t·∫°i
                st.write("Current data types:")
                st.write(st.session_state.my_df.dtypes)

                selected_column = st.selectbox("Column to convert", st.session_state.my_df.columns, key="convert_column")
                new_dtype = st.selectbox("New data type", ["int32", "int64", "float32", "float64", "object"], key="new_dtype")

                if st.button("Convert"):
                    # √Åp d·ª•ng h√†m convert_column_dtype cho c·ªôt ƒë∆∞·ª£c ch·ªçn
                    st.session_state.my_df = convert_column_dtype(st.session_state.my_df, selected_column, new_dtype)
                    st.write(f"Converted column '{selected_column}' to {new_dtype}")
                    st.write(st.session_state.my_df.dtypes)
                
            with tab6:
                st.header("Check Outliers")
                st.write("Choose column to check outliers")
                
                selected_column = st.selectbox("Column", st.session_state.my_df.columns, key="outlier_select")
                
                # t·∫°o 1 container ch·ª©a bi·ªÉu ƒë·ªì trong tr∆∞·ªùng h·ª£p c√≥ outlier
                container_diagram =  st.empty()
                
                with container_diagram.container():
                    check_outliers_plot(st.session_state.my_df, selected_column)
                    
                if st.button('Handle Outliers'):
                    st.session_state.my_df = remove_outliers(df, selected_column)
                    st.write('remove successfully')
                    # sau khi remove successfully th√¨ container s·∫Ω ƒë∆∞·ª£c l√†m r·ªóng
                    container_diagram.empty()
            with tab7:
                st.header("Encode Categorical Variables")
                
                # L·ª±a ch·ªçn ph∆∞∆°ng ph√°p m√£ h√≥a t·ª´ ng∆∞·ªùi d√πng
                encode_method = st.selectbox("Select encoding method:", ["One-Hot Encoding", "Ordinal Encoding", "Label Encoding"])

                # M√£ h√≥a d·ªØ li·ªáu theo ph∆∞∆°ng ph√°p ƒë∆∞·ª£c ch·ªçn
                if encode_method == "One-Hot Encoding":
                    column = st.selectbox("Select column to encode:", st.session_state.my_df.columns)
                    df_encoded = one_hot_encode(st.session_state.my_df, column)
                elif encode_method == "Ordinal Encoding":
                    column = st.selectbox("Select column to encode:", st.session_state.my_df.columns)
                    df_encoded = ordinal_encode(st.session_state.my_df, column)
                else:  # Label Encoding
                    column = st.selectbox("Select column to encode:", st.session_state.my_df.columns)
                    df_encoded = label_encode(st.session_state.my_df, column)

                # Hi·ªÉn th·ªã k·∫øt qu·∫£
                st.write("Encoded DataFrame:")
                st.write(df_encoded)

            with tab8:
                st.header("Save dataset")
    
                # Ki·ªÉm tra n·∫øu c√≥ DataFrame v√† ƒë√£ clean data
                if 'my_df' in st.session_state and st.session_state.my_df is not None:
                    st.write("Your cleaned dataset:")
                    st.write(st.session_state.my_df.head())
                    
                    # X√°c ƒë·ªãnh t√™n file m·∫∑c ƒë·ªãnh
                    default_filename = None
                    if uploaded_files:
                        # N·∫øu c√≥ file t·∫£i l√™n, s·ª≠ d·ª•ng t√™n file ƒë·∫ßu ti√™n k√®m theo "_cleaned.csv"
                        default_filename = uploaded_files[0].name.split('.')[0] + "_cleaned.csv"
                    filename = st.text_input("Enter a filename to save as:", default_filename)
                    # Th√™m n√∫t ƒë·ªÉ l∆∞u dataset
                    if st.button("Save Cleaned Dataset"):
                        
                        if filename.strip() == "":
                            st.warning("Please enter a valid filename.")
                        else:
                            save_dataset(st.session_state.my_df, filename)
                            
                            # Hi·ªÉn th·ªã link ƒë·ªÉ t·∫£i file v·ªÅ
                            download_link = get_download_link(st.session_state.my_df, filename, "Click here to download the cleaned dataset")
                            st.markdown(download_link, unsafe_allow_html=True)
                else:
                    st.warning("No cleaned dataset available. Please clean your data first.")
            
            
            
            
            
            
            

        
    


    



    
    

    